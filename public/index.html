<!DOCTYPE html>
<html lang="es">
<head>

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">

<title>CONSIA AVATAR CORE</title>

<style>
body{
  margin:0;
  background:black;
  overflow:hidden;
  font-family:Arial;
}

#status{
  position:absolute;
  bottom:30px;
  width:100%;
  text-align:center;
  color:white;
  letter-spacing:4px;
  opacity:0.7;
}
</style>

</head>
<body>

<div id="status">CONSIA AVATAR ACTIVE</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>

<script>

// SCENE
const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(
  60,
  innerWidth/innerHeight,
  0.1,
  1000
);
camera.position.z = 2;

const renderer = new THREE.WebGLRenderer({antialias:true});
renderer.setSize(innerWidth,innerHeight);
document.body.appendChild(renderer.domElement);

// LIGHT
const light = new THREE.PointLight(0xffffff,2);
light.position.set(0,2,2);
scene.add(light);

// AVATAR (placeholder humanoid)
const geo = new THREE.SphereGeometry(0.8,64,64);
const mat = new THREE.MeshStandardMaterial({
  color:0x00ffff,
  metalness:0.7,
  roughness:0.2
});
const avatar = new THREE.Mesh(geo,mat);
scene.add(avatar);

// AUDIO LIP SYNC
navigator.mediaDevices.getUserMedia({audio:true})
.then(stream=>{

  const ctx = new AudioContext();
  const src = ctx.createMediaStreamSource(stream);
  const analyser = ctx.createAnalyser();
  src.connect(analyser);

  const data = new Uint8Array(analyser.frequencyBinCount);

  function audioLoop(){
    analyser.getByteFrequencyData(data);

    let volume=0;
    for(let i=0;i<data.length;i++){
      volume+=data[i];
    }
    volume/=data.length;

    avatar.scale.y = 1 + volume/300; // lip sync pulse

    requestAnimationFrame(audioLoop);
  }

  audioLoop();
});

// FACE TRACKING
navigator.mediaDevices.getUserMedia({video:true})
.then(stream=>{

  const video = document.createElement("video");
  video.srcObject = stream;
  video.play();

  const faceMesh = new FaceMesh({
    locateFile: file =>
      `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
  });

  faceMesh.onResults(results=>{
    if(results.multiFaceLandmarks){

      const face = results.multiFaceLandmarks[0];

      const x = face[1].x - 0.5;
      const y = face[1].y - 0.5;

      avatar.rotation.y = x*2;
      avatar.rotation.x = y*2;
    }
  });

  async function detect(){
    await faceMesh.send({image:video});
    requestAnimationFrame(detect);
  }

  detect();
});

// WAKE WORD (keyword detect base)
let listening=false;

navigator.mediaDevices.getUserMedia({audio:true})
.then(stream=>{

  const recognition =
    new webkitSpeechRecognition();

  recognition.continuous=true;

  recognition.onresult=e=>{

    const text =
      e.results[e.results.length-1][0]
      .transcript
      .toLowerCase();

    if(text.includes("consia")){
      listening=true;
      mat.color.set(0xff00ff);
      console.log("WAKE WORD DETECTED");
    }
  };

  recognition.start();
});

// VOICE STREAM SOCKET
const socket =
  new WebSocket("wss://api.consia.world/ws/voice");

socket.onopen=()=>{
  console.log("VOICE STREAM ACTIVE");
};

// EMOTION AI COLOR STATES
setInterval(()=>{

  const emotion=Math.random();

  if(emotion<0.3)
    mat.color.set(0x00ffff);
  else if(emotion<0.6)
    mat.color.set(0xff00ff);
  else
    mat.color.set(0x0044ff);

},2000);

// ANIMATE
function animate(){
  requestAnimationFrame(animate);
  renderer.render(scene,camera);
}
animate();

</script>
</body>
</html>
